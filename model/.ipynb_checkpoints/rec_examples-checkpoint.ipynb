{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# About this notebook:\n",
    "## Steps:\n",
    "#### 1. Ingest user selected filters\n",
    "#### 2. Filter plants\n",
    "#### 3. Recommendation using item-simialrity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/czhu/opt/anaconda3/lib/python3.8/site-packages/pandas/core/computation/expressions.py:20: UserWarning: Pandas requires version '2.7.3' or newer of 'numexpr' (version '2.7.1' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "import copy\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.cluster import KMeans, DBSCAN, SpectralClustering\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "pd.set_option('display.max_columns', None)\n",
    "from sklearn.metrics import silhouette_samples, silhouette_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../plant_master_v4.csv\r\n"
     ]
    }
   ],
   "source": [
    "!ls '../../plant_master_v4.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter json path\n",
    "pref_path = 'filters.json'\n",
    "# filter_url = 'http://20.127.87.137/recommendations/data'\n",
    "\n",
    "# plant data path\n",
    "# plant_path = 'plant_master_v4.csv'\n",
    "plant_path ='../../plant_master_v4.csv'\n",
    "\n",
    "# environment data path\n",
    "envr_path = 'envr.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User preference ingestion\n",
    "\n",
    "TODO: change UI filters to UI filters to the following set:\n",
    "\n",
    "type: {'0': 'edible', '1': 'flowering', '2': 'greens', '3': 'hybrid'}\n",
    "\n",
    "height: range(min, max)\n",
    "\n",
    "width: range(min, max)\n",
    "\n",
    "smell:(1|0)\n",
    "\n",
    "showy :(1|0)\n",
    "\n",
    "sun: {'0': 'full sun',\n",
    "              '2': 'full shade',\n",
    "              '4': 'part sun'}\n",
    "              \n",
    "maintenance:  \n",
    "             {'0': 'medium', \n",
    "              '1': 'low', \n",
    "              '2': 'high'}\n",
    "month: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opening JSON file\n",
    "# with open(pref_path) as json_file:\n",
    "#     user = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## current filters that work for the master_v3\n",
    "test = {\n",
    "    'type': \n",
    "             {'1': 'hybrid'},  #, , '2': 'greens', '3': 'hybrid'\n",
    "    'height': \n",
    "             {'max': 10, \n",
    "              'min': 0}, \n",
    "    'width':\n",
    "             {'max': 30, \n",
    "              'min': 0},\n",
    "    'smell': \n",
    "             {'min': 0}, \n",
    "    'showy': \n",
    "             {'max': 0},\n",
    "    'maintenance': \n",
    "             {'1': 'high'},\n",
    "    'zipcode': \n",
    "             {'ip': '67.170.250.166',\n",
    "              'zip': '83703'},\n",
    "    'month': {'0': 6}\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# envr = pd.read_csv(envr_path, index_col=0, dtype={'zip_code': 'string'})\n",
    "# envr.zip_code.sample(5)\n",
    "\n",
    "# 45507     20850\n",
    "# 24323     11385\n",
    "# 188493    83703\n",
    "# 23008     10970\n",
    "# 59375     27560"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: adapt ingest_filters to new filter json format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# variables\n",
    "def ingest_filters(j):\n",
    "    params = []\n",
    "    envr = []\n",
    "    for _, typ in j['type'].items():\n",
    "        type_col = typ\n",
    "    for _, sm in j['smell'].items():\n",
    "        smell = sm\n",
    "    for _, sw in j['showy'].items():\n",
    "        showy = sw\n",
    "#     for _, su in j['sun'].items():\n",
    "#         sun = su\n",
    "    for _, mt in j['maintenance'].items():\n",
    "        if mt == 'high':\n",
    "            maintenance = ['low', 'medium', 'high', 'none']\n",
    "        elif mt == 'medium':\n",
    "            maintenance = ['low', 'medium', 'none']\n",
    "        else: \n",
    "            maintenance = ['low', 'none']\n",
    "        \n",
    "            \n",
    "    for _, mn in j['month'].items():\n",
    "        month = mn\n",
    "\n",
    "    height_max = j['height']['max']\n",
    "    height_min = j['height']['min']\n",
    "    width_max = j['width']['max']\n",
    "    width_min = j['width']['min']\n",
    "    zipcode = j['zipcode']['zip']\n",
    "    \n",
    "    params = [type_col, smell, showy, maintenance, height_max, height_min, width_max, width_min]\n",
    "    envr = [zipcode, month]\n",
    "    \n",
    "    return envr, params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "envr_filters, plant_filters = ingest_filters(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# envr = pd.read_csv(envr_path, index_col=0, dtype={'zip_code': 'string'})\n",
    "# envr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use user's zipcode, month to find temperature/sun/zone\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Full sun - 6 or more hours of direct sun per day\n",
    "Part sun - 4 to 6 hours of direct sun per day, including some afternoon sun\n",
    "Part shade - 4 to 6 hours of direct sun per day, mostly before midday\n",
    "Full shade - less than 4 hours of direct sun per day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def envr_features(envr_path, envr_filters):\n",
    "    # unpack filters\n",
    "    zipcode, month = envr_filters\n",
    "    \n",
    "    def temp_bucket(x):\n",
    "        x =round(x)\n",
    "        if x <= 55:\n",
    "            o = 'low'\n",
    "        elif x in range(56, 66):\n",
    "            o = 'cool'\n",
    "        elif x in range(66, 75):\n",
    "            o = 'mild'\n",
    "        elif x in range(75, 85):\n",
    "            o = 'warm'\n",
    "        else:\n",
    "            o = 'hot'\n",
    "        return o\n",
    "\n",
    "    def sun_bucket(x):\n",
    "        '''\n",
    "        Full sun - 6 or more hours of direct sun per day\n",
    "        Part sun - 4 to 6 hours of direct sun per day, including some afternoon sun\n",
    "        Part shade - 4 to 6 hours of direct sun per day, mostly before midday\n",
    "        Full shade - less than 4 hours of direct sun per day\n",
    "        '''\n",
    "        x = round(x)\n",
    "        if x <= 4:\n",
    "            out = 'full shade'\n",
    "        elif x in range(4, 7):\n",
    "            out = 'part sun'\n",
    "        elif x in range(6, 26):\n",
    "            out = 'full sun'\n",
    "        return out\n",
    "\n",
    "    envr = pd.read_csv(envr_path, index_col=0, dtype={'zip_code': 'string'})\n",
    "    loc_info = envr[(envr['zip_code'] == zipcode) & (envr['Month'] == month)].to_dict()\n",
    "    temp_cat = temp_bucket(list(loc_info['tmin'].values())[0])\n",
    "    zone = list(loc_info['zone'].values())[0]\n",
    "    sun_cat = sun_bucket(list(loc_info['GHI_per_day'].values())[0])\n",
    "    \n",
    "    return zone, sun_cat, temp_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "zone, sun_cat, temp_cat = envr_features(envr_path, envr_filters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter plant data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read plant data\n",
    "\n",
    "def subset_plant(plant_path, plant_filters):\n",
    "    \n",
    "    \"\"\" input: \n",
    "            plant_path: path to plant master data\n",
    "            filter_params: filters ingested from front-end json and environment features\n",
    "        output: \n",
    "            subset of plants\n",
    "    \"\"\"\n",
    "    # read plant data\n",
    "    plant_df = pd.read_csv(plant_path, index_col=0)\n",
    "    \n",
    "    # unpack filters\n",
    "    type_col, smell, showy, maintenance, height_max, height_min, width_max, width_min = plant_filters\n",
    "    \n",
    "    sub = plant_df[(plant_df[type_col] == 1) \n",
    "                   & (plant_df['smell']== smell) \n",
    "                   & (plant_df['showy']== showy) \n",
    "                   & (plant_df['sun']== sun_cat) \n",
    "                   & (plant_df['maintenance'].isin(maintenance))\n",
    "                   & ((plant_df['height']<=height_max) & (plant_df['height']>=height_min)) \n",
    "                   & ((plant_df['width']<=width_max) & (plant_df['height']>=width_min)) \n",
    "                   & (plant_df['zones'].isin([zone-1, zone, zone+1]))\n",
    "                   & (plant_df['temp_bucket']== temp_cat)]\n",
    "\n",
    "    # remove the filter columns\n",
    "    cols_to_drop = ['smell', 'showy','sun', 'maintenance', 'height', 'width', 'zones', 'temp_bucket', type_col]\n",
    "    sub.drop(columns=cols_to_drop, inplace=True)\n",
    "    \n",
    "    return sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-12-87ddbbc56266>:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sub.drop(columns=cols_to_drop, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "df = subset_plant(plant_path, plant_filters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['attracts', 'common', 'water', 'special_feature', 'propagation',\n",
       "       'problem_solvers', 'flowering', 'annual', 'perennial', 'biennial',\n",
       "       'drought', 'air_pollution', 'dry_soil', 'wet_soil', 'clay_soil',\n",
       "       'rain_garden', 'good_for_containers', 'water_plant', 'm_type', 'edible',\n",
       "       'bloom_season', 'greens'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Randomly select samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# randomely select n samples\n",
    "N_REC = 1\n",
    "RAM_PLANT = df.common.sample(N_REC).values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pca(df):\n",
    "    \"\"\" function: one-hot encoded catgorical features concatonated with binary feature\n",
    "        input: subset of plant\n",
    "        output: dimentionality reduced pca data\n",
    "    \"\"\"\n",
    "    \n",
    "    cat_cols = ['attracts', 'water', 'special_feature', 'propagation',\n",
    "           'problem_solvers', 'm_type', 'bloom_season']\n",
    "\n",
    "    categorical_preprocessor = OneHotEncoder(handle_unknown=\"ignore\")\n",
    "    encoded_columns = categorical_preprocessor.fit_transform(df[cat_cols])\n",
    "    processed_data = encoded_columns.todense()\n",
    "\n",
    "    while True:\n",
    "        try:\n",
    "            pca = PCA(n_components=processed_data.shape[1],random_state=42)\n",
    "            pca_model = pca.fit(processed_data)\n",
    "\n",
    "        except ValueError: \n",
    "            pca_data = processed_data\n",
    "            break\n",
    "\n",
    "        else:\n",
    "            ratio = pca_model.explained_variance_ratio_\n",
    "            cum_sum_eigenvalues = np.cumsum(ratio)\n",
    "\n",
    "            # select 95% cutoff\n",
    "            cutoff = np.where(cum_sum_eigenvalues>0.95)[0][0]\n",
    "            pca = PCA(n_components=cutoff,random_state=42)\n",
    "            pca_data = pca.fit_transform(processed_data)\n",
    "            break\n",
    "\n",
    "    bin_cols = [col for col in df.columns if col not in cat_cols or not 'common']\n",
    "    target = df.pop('common').tolist()\n",
    "    bin_cols.remove('common')\n",
    "    bin_train = np.array(df[bin_cols])\n",
    "\n",
    "    features = np.concatenate((bin_train, pca_data),axis=1) \n",
    "    \n",
    "    return features, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "features, target = pca(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mock user selection\n",
    "\n",
    "USER_PREF_PLANT = RAM_PLANT\n",
    "NUM_SIMILAR = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "DOT = 'dot'\n",
    "COSINE = 'cosine'\n",
    "\n",
    "def compute_scores(query_embedding, item_embeddings, measure=COSINE):\n",
    "  \"\"\"Computes the scores of the candidates given a query.\n",
    "  Args:\n",
    "    query_embedding: a vector of shape [k], representing the query embedding.\n",
    "    item_embeddings: a matrix of shape [N, k], such that row i is the embedding\n",
    "      of item i.\n",
    "    measure: a string specifying the similarity measure to be used. Can be\n",
    "      either DOT or COSINE.\n",
    "  Returns:\n",
    "    scores: a vector of shape [N], such that scores[i] is the score of item i.\n",
    "  \"\"\"\n",
    "  u = query_embedding\n",
    "  V = item_embeddings\n",
    "  if measure == COSINE:\n",
    "    V = V / np.linalg.norm(V, axis=1, keepdims=True)\n",
    "    u = u / np.linalg.norm(u)\n",
    "  scores = u.dot(V.T)\n",
    "  return scores\n",
    "\n",
    "\n",
    "def recommendation(features, target, plant, df, NUM_SIMILAR):\n",
    "    ''' \n",
    "    funtion: recommendation engine\n",
    "    input:\n",
    "        features: features for cosine similarity calc.\n",
    "        target: names of plants\n",
    "        plant: randomly selected item, used to find similarlity for\n",
    "        df: subset of plant dataframe\n",
    "        NUM_SIMILAR: num of recommendation to return\n",
    "    output:\n",
    "        df of top n similar items\n",
    "    '''\n",
    "    \n",
    "    item_idx = target.index(plant)\n",
    "    query_vec = features[item_idx][:]\n",
    "\n",
    "    scores = compute_scores(query_vec, features, measure=COSINE)\n",
    "    df['cosine'] = scores\n",
    "\n",
    "    df['target']= target\n",
    "    score_df = pd.DataFrame(df.groupby('target')['cosine'].mean().sort_values(ascending=False))\n",
    "    sim_plants = score_df[:NUM_SIMILAR]\n",
    "\n",
    "    return sim_plants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_items = recommendation(features, target, USER_PREF_PLANT, df, NUM_SIMILAR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27560"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "27560"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'kale'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "USER_PREF_PLANT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cosine</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>target</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>kohlrabi</th>\n",
       "      <td>0.861492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cabbage</th>\n",
       "      <td>0.735594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kale</th>\n",
       "      <td>0.696734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>broccoli</th>\n",
       "      <td>0.616344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lettuce</th>\n",
       "      <td>0.570836</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            cosine\n",
       "target            \n",
       "kohlrabi  0.861492\n",
       "cabbage   0.735594\n",
       "kale      0.696734\n",
       "broccoli  0.616344\n",
       "lettuce   0.570836"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim_items"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
